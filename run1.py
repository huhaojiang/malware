#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@TIME: 2019/11/14 15:20
@FILE: run.py
@AUTHOR: HU
"""
# import train_lstm
# import train_lstm2
# import train_lstm3
# import train_textcnn
import stack
import lgbm
import pandas as pd
import numpy as np
from sklearn.utils import shuffle
from sklearn.feature_selection import VarianceThreshold

if __name__ == '__main__':
    df = pd.read_csv("dll_label.csv", chunksize=10000)
    df1 = pd.read_csv("exe_label.csv", chunksize=10000)
    name = []
    label = []
    black = []
    white = []
    for x in df:
        black.append(x.loc[x["label"] == 1])
        white.append(x.loc[x["label"] == 0])
    for y in df1:
        black.append(y.loc[y["label"] == 1])
        white.append(y.loc[y["label"] == 0])
    df_black = pd.concat(black, axis=0)
    df_white = pd.concat(white, axis=0)
    print(df_black.shape)
    print(df_white.shape)
    #exit()
    len_b = int(df_black.shape[0] * 0.9)
    len_w = int(df_white.shape[0] * 0.9)

    # df_black = shuffle(df_black)
    # df_white = shuffle(df_white)

    train_df_black = df_black.iloc[:len_b, :]
    train_df_white = df_white.iloc[:len_w, :]
    train_df = pd.concat([train_df_black, train_df_white])
    train_df = shuffle(train_df)
    print(train_df.shape)

    test_df_black = df_black.iloc[len_b:, :]
    test_df_white = df_white.iloc[len_w:, :]
    test_df = pd.concat([test_df_black, test_df_white])
    test_df = shuffle(test_df)
    test_df1 = test_df.copy()
    print(test_df.shape)

    test_labels = np.asarray([int(x) for x in test_df["label"].values])
    labels = np.asarray([int(x) for x in train_df["label"].values])
    del train_df['name']
    del test_df['name']
    # train_df = train_df.loc[train_df['label'] != 2, ['dict2_one_max', 'dict2_zero_max', 'api_in_dict_one_pro_mean','api_in_dict_zero_pro_mean', 'api_in_dict_one_pro_max','api_in_dict_zero_pro_max']]
    # test_df = test_df.loc[test_df['label'] != 2, ['dict2_one_max', 'dict2_zero_max', 'api_in_dict_one_pro_mean','api_in_dict_zero_pro_mean', 'api_in_dict_one_pro_max','api_in_dict_zero_pro_max']]
    del train_df['label']
    del test_df['label']
    #test_labels = test_labels.reshape(-1, 1)
    #labels = labels.reshape(-1, 1)
    x_train_padded_seqs = train_df.copy()
    x_test_padded_seqs = test_df.copy()
    # for i in train_df["api"].values:
    #     i = [int(x) for x in i.split(" ")]
    #     x_train_padded_seqs.append(i)
    # for i in test_df["api"].values:
    #     i = [int(x) for x in i.split(" ")]
    #     x_test_padded_seqs.append(i)
    #
    x_train_padded_seqs = np.asarray(x_train_padded_seqs)
    x_test_padded_seqs = np.asarray(x_test_padded_seqs)
    print(x_train_padded_seqs.shape)
    v = VarianceThreshold(threshold=0.1)
    v.fit_transform(x_train_padded_seqs, labels)
    var = v.variances_
    var1 = [True if x >=0.1 else False for x in var]
    print(var1)
    x_train_padded_seqs = x_train_padded_seqs[:, var1]
    x_test_padded_seqs = x_test_padded_seqs[:, var1]
    print(labels)
    print(type(labels))
    # print("="*50 + "train_lstm" + "="*50)
    # train_lstm.main(x_train_padded_seqs, x_test_padded_seqs, labels, test_labels)
    print("=" * 50 + "train_lstm2" + "=" * 50)
    # train_lstm2.main(x_train_padded_seqs, x_test_padded_seqs, labels, test_labels, test_df)
    # print("=" * 50 + "train_lstm3" + "=" * 50)
    # train_lstm3.main(x_train_padded_seqs, x_test_padded_seqs, labels, test_labels)
    # print("=" * 50 + "train_textcnn" + "=" * 50)
    # train_textcnn.main(x_train_padded_seqs, x_test_padded_seqs, labels, test_labels)
    # print("=" * 50 + "stack_result" + "=" * 50)
    # stack_result.main(x_test_padded_seqs, labels, test_labels)
    stack.main(x_train_padded_seqs, x_test_padded_seqs, labels, test_labels)
    print("=" * 50 + "finish" + "=" * 50)

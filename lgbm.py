#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@TIME: 2020/1/19 11:23
@FILE: lgbm.py
@AUTHOR: HU
"""
import lightgbm as lgb
import numpy as np
import pickle
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import *


def main(x_train_padded_seqs, x_out_padded_seqs, labels, test_labels):
    # meta_train = np.zeros(shape=(len(x_train_padded_seqs), 2))
    meta_test = np.zeros(shape=(len(x_out_padded_seqs), 2))
    skf = StratifiedKFold(n_splits=5, random_state=4, shuffle=True)
    dout = x_out_padded_seqs

    for i, (tr_ind, te_ind) in enumerate(skf.split(x_train_padded_seqs, labels)):
        # meta_test = np.zeros(shape=(len(x_out_padded_seqs), 2))
        print('FOLD: {}'.format(str(i)))
        X_train, X_train_label = x_train_padded_seqs[tr_ind], labels[tr_ind]
        X_val, X_val_label = x_train_padded_seqs[te_ind], labels[te_ind]
        dtrain = lgb.Dataset(X_train, np.array(X_train_label))
        dtest = lgb.Dataset(X_val, np.array(X_val_label))# , reference=dtrain)  # label可以不要，此处需要是为了测试效果
        params = {'num_leaves': 60, #结果对最终效果影响较大，越大值越好，太大会出现过拟合
          'min_data_in_leaf': 30,
          'objective': 'binary', #定义的目标函数
          'max_depth': -1,
          'learning_rate': 0.03,
          "min_sum_hessian_in_leaf": 6,
          "boosting": "gbdt",
          "feature_fraction": 0.9,	#提取的特征比率
          "bagging_freq": 1,
          "bagging_fraction": 0.8,
          "bagging_seed": 11,
          "lambda_l1": 0.1,				#l1正则
          # 'lambda_l2': 0.001,		#l2正则
          "verbosity": -1,
          "nthread": -1,				#线程数量，-1表示全部线程，线程越多，运行的速度越快
          'metric': {'binary_logloss', 'auc'},	##评价函数选择
          "random_state": 2019,	#随机数种子，可以防止每次运行的结果不一致
          #'device': 'gpu' ##如果安装的事gpu版本的lightgbm,可以加快运算
          }
        gbm = lgb.train(params, dtrain, num_boost_round=50000, valid_sets=dtest, early_stopping_rounds=50)
        with open("gbmmodel" + "_{}".format(str(i)) + ".pkl", "wb") as f:
            pickle.dump(gbm, f)
            # gbm = pickle.load(f)
        preds = gbm.predict(dout)
        # for importance_type in ('weight', 'gain', 'cover', 'total_gain', 'total_cover'):
        #     print(bst.get_score(importance_type=importance_type))
        meta_test = preds
        print(preds)
        # meta_test /= 5.0
        print(meta_test)
        out_pred_ = [1 if x > 0.5 else 0 for x in preds]
        # test_df1.insert(0, "pred", out_pred_)
        # test_df1.to_csv("../data/test_df1.csv", index=False)
        print(test_labels)
        print(out_pred_)
        acc = accuracy_score(test_labels, out_pred_)
        f1 = f1_score(test_labels, out_pred_, average='macro')
        pre = precision_score(test_labels, out_pred_, average='macro')
        rec = recall_score(test_labels, out_pred_, average='macro')
        print("混淆矩阵")
        print(confusion_matrix(test_labels, out_pred_))
        print("accuray: {}, f1score: {}, precision: {}, recall: {}".format(acc, f1, pre, rec))
    
